{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "799930f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import nbimporter\n",
    "import copy\n",
    "import numpy as np\n",
    "from Strategy import apply_strategy\n",
    "from Generate_deck import generate_deck\n",
    "from Deal_hand import deal_hand\n",
    "from Q_learning import QLearningAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81268b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackjackNode:\n",
    "    def __init__(self, player_hand, dealer_hand, deck, parent=None, is_terminal=False):\n",
    "        self.player_hand = player_hand\n",
    "        self.dealer_hand = dealer_hand\n",
    "        self.deck = deck\n",
    "        self.parent = parent\n",
    "        self.is_terminal = is_terminal\n",
    "        self.visits = 0\n",
    "        self.wins = 0\n",
    "        self.children = []\n",
    "\n",
    "def mcts(node, q_learning_agent, iterations):\n",
    "    for i in range(iterations):\n",
    "        selected_node = select(node, q_learning_agent)\n",
    "        expanded_node = expand(selected_node)\n",
    "        simulation_result, is_terminal, action_taken = simulate(expanded_node, q_learning_agent)\n",
    "        backpropagate(expanded_node, simulation_result, q_learning_agent, action_taken)\n",
    "    return best_child(node).player_hand\n",
    "\n",
    "\n",
    "\n",
    "def select(node, q_learning_agent):\n",
    "    while node.children:\n",
    "        node = best_uct_q(node, q_learning_agent)\n",
    "    return node\n",
    "\n",
    "def expand(node):\n",
    "    draw_child_deck = copy.copy(node.deck)\n",
    "    if node.player_hand is None:\n",
    "        player_hand = []\n",
    "    else:\n",
    "        player_hand = node.player_hand.copy()\n",
    "\n",
    "    draw_card_value = draw_card(draw_child_deck)\n",
    "    player_hand.append(draw_card_value)\n",
    "    \n",
    "    draw_child = BlackjackNode(player_hand=player_hand, dealer_hand=node.dealer_hand, deck=draw_child_deck, parent=node, is_terminal=False)\n",
    "    stay_child = BlackjackNode(player_hand=node.player_hand, dealer_hand=node.dealer_hand, deck=node.deck, parent=node, is_terminal=True)\n",
    "    \n",
    "    node.children.extend([draw_child, stay_child])\n",
    "    return draw_child\n",
    "\n",
    "def simulate(node, q_learning_agent):\n",
    "    player_hand = node.player_hand\n",
    "    dealer_hand = node.dealer_hand\n",
    "    deck = node.deck.copy()\n",
    "\n",
    "    # Décider de l'action à prendre (Hit ou Stand)\n",
    "    action = q_learning_agent.choose_action(get_state_index_from_node(node))\n",
    "    \n",
    "    # Simuler l'action\n",
    "    if action == 1:  # Supposons que 1 représente Hit\n",
    "        drawn_card = draw_card(deck)\n",
    "        player_hand.append(drawn_card)\n",
    "        # Mettre à jour l'état du noeud après avoir tiré une carte\n",
    "        node.player_hand = player_hand\n",
    "\n",
    "    # Calculer la récompense et l'état après l'action\n",
    "    reward, is_terminal = calculate_reward_and_terminal(node)\n",
    "    next_state_index = get_state_index_from_node(node)\n",
    "\n",
    "    # Mettre à jour l'agent Q-learning\n",
    "    q_learning_agent.update(get_state_index_from_node(node), action, reward, next_state_index)\n",
    "\n",
    "    return reward, is_terminal, action\n",
    "\n",
    "def backpropagate(node, result, q_learning_agent, action_taken):\n",
    "    while node is not None:\n",
    "        node.visits += 1\n",
    "        if result is not None:\n",
    "            node.wins += result\n",
    "        if node.parent is not None:\n",
    "            state_index = get_state_index_from_node(node)\n",
    "            next_state_index = get_state_index_from_node(node.parent)\n",
    "            q_learning_agent.update(state_index, action_taken, result, next_state_index)\n",
    "        node = node.parent\n",
    "\n",
    "\n",
    "def best_uct_q(node, q_learning_agent):\n",
    "    exploration_weight = 1.0 / math.sqrt(2.0)\n",
    "\n",
    "    def uct_q_value(child):\n",
    "        state_index = get_state_index_from_node(child)\n",
    "        q_value = np.max(q_learning_agent.Q_table[state_index])\n",
    "\n",
    "        if child.visits == 0:\n",
    "            return float('inf')\n",
    "\n",
    "        uct_val = (child.wins / child.visits) + exploration_weight * math.sqrt(math.log(node.visits) / child.visits) + q_value\n",
    "\n",
    "        return uct_val\n",
    "\n",
    "    return max(node.children, key=uct_q_value)\n",
    "\n",
    "def best_child(node):\n",
    "    best_child = max(node.children, key=lambda child: child.wins)\n",
    "    return best_child\n",
    "\n",
    "def draw_card(deck):\n",
    "    if not deck:\n",
    "        raise IndexError(\"Cannot choose from an empty deck\")\n",
    "    card = random.choice(deck)\n",
    "    deck.remove(card)\n",
    "    return card\n",
    "\n",
    "def play_game(player_hand, dealer_hand, deck):\n",
    "    player_score = calculate_score(player_hand)\n",
    "    dealer_score = calculate_score(dealer_hand)\n",
    "\n",
    "    if player_score > 21:\n",
    "        result = {\"result\": \"loss\"}\n",
    "    elif dealer_score > 21:\n",
    "        result = {\"result\": \"win\"}\n",
    "    elif player_score > dealer_score:\n",
    "        result = {\"result\": \"win\"}\n",
    "    elif player_score < dealer_score:\n",
    "        result = {\"result\": \"loss\"}\n",
    "    else:\n",
    "        result = {\"result\": \"draw\"}\n",
    "\n",
    "    return result\n",
    "\n",
    "def calculate_score(hand):\n",
    "    # Calcul du score du joueur ou du croupier\n",
    "    score = 0\n",
    "    num_aces = 0\n",
    "\n",
    "    for card in hand:\n",
    "        if card['value'] in ['J', 'Q', 'K']:\n",
    "            score += 10\n",
    "        elif card['value'] == 'A':\n",
    "            num_aces += 1\n",
    "        else:\n",
    "            score += int(card['value'])\n",
    "\n",
    "    # Traitement des As\n",
    "    while num_aces > 0 and score + 10 <= 21:\n",
    "        score += 10\n",
    "        num_aces -= 1\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_state_index_from_node(node):\n",
    "    total_hand = calculate_score(node.player_hand)\n",
    "    has_usable_ace = \"A\" in [card['value'] for card in node.player_hand] and total_hand + 10 <= 21\n",
    "\n",
    "    state_index = total_hand - 4  # Ajustement pour que l'index commence à 0\n",
    "    if has_usable_ace:\n",
    "        state_index += 18  # Décaler de 18 si un as utilisable est présent\n",
    "\n",
    "    # S'assurer que l'indice est dans la plage [0, 35]\n",
    "    if state_index < 0:\n",
    "        state_index = 0\n",
    "    elif state_index >= 36:\n",
    "        state_index = 35\n",
    "\n",
    "    return state_index\n",
    "\n",
    "\n",
    "\n",
    "def calculate_reward_and_terminal(node):\n",
    "    \n",
    "    player_score = calculate_score(node.player_hand)\n",
    "    dealer_score = calculate_score(node.dealer_hand)\n",
    "\n",
    "    if player_score > 21:\n",
    "        return -1, True  # Pénalité pour dépassement, état terminal\n",
    "    elif dealer_score > 21 or player_score == 21:\n",
    "        return 1, True  # Récompense pour gagner, état terminal\n",
    "    elif node.is_terminal:  # Si le nœud est marqué comme terminal (par exemple, après un \"Stand\")\n",
    "        if player_score > dealer_score:\n",
    "            return 1, True  # Gagné\n",
    "        elif player_score < dealer_score:\n",
    "            return -1, True  # Perdu\n",
    "        else:\n",
    "            return 0, True  # Égalité\n",
    "    return 0, False  # Aucune récompense, état non terminal\n",
    "\n",
    "    \n",
    "def simulate_games(number_of_games, q_learning_agent):\n",
    "    results = {'wins': 0, 'losses': 0, 'draws': 0}\n",
    "    for _ in range(number_of_games):\n",
    "        deck = generate_deck()\n",
    "        player_hand = deal_hand(deck)\n",
    "        dealer_hand = deal_hand(deck)\n",
    "\n",
    "        mcts_decision = mcts(BlackjackNode(player_hand, dealer_hand, deck, None, False), q_learning_agent, 1000)\n",
    "\n",
    "        game_result = play_game(mcts_decision, dealer_hand, deck)\n",
    "\n",
    "        if game_result['result'] == 'win':\n",
    "            results['wins'] += 1\n",
    "        elif game_result['result'] == 'loss':\n",
    "            results['losses'] += 1\n",
    "        else:\n",
    "            results['draws'] += 1\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a93c029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_etats = 36 \n",
    "nombre_actions = 2\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.99\n",
    "epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "epsilon_decay = 0.995\n",
    "\n",
    "q_learning_agent = QLearningAgent(nombre_etats, nombre_actions, learning_rate, discount_factor, epsilon, min_epsilon, epsilon_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0ba41ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats de la simulation :\n",
      "{'wins': 60, 'losses': 133, 'draws': 7}\n"
     ]
    }
   ],
   "source": [
    "number_of_games = 200\n",
    "strategy = \"mcts\"\n",
    "results = simulate_games(number_of_games, q_learning_agent)\n",
    "\n",
    "print(\"Résultats de la simulation :\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781f4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
